{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this demo will learn how to persist the model for future use \n",
    "from sklearn.datasets import load_iris\n",
    "# use iris dataset object to create an instance of the dataset\n",
    "iris_dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view feature names of the dataset\n",
    "iris_dataset.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view target of the dataset\n",
    "print(iris_dataset.target_names)\n",
    "iris_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features and target objects\n",
    "X_features = iris_dataset.data\n",
    "Y_target=iris_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create object with new values for prediction\n",
    "X_new=[[3,5,4,1],[5,3,4,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the logistic regression estimator(trying to predict the outcome using logistic regression model)\n",
    "# first import logistic regression class and instantiate it\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit data into logistic regression estimator\n",
    "logreg.fit(X_features,Y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the outcome using Logistic regression estimator\n",
    "logreg.predict(X_new) #My output is wrong. It should be array([0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's now time to predict the outcome for new observation which we created as we can see it matches the target labels.\n",
    "# 0 and 2 from 0,1&2. This means that model is working as expected. so Let's see how u can save it so u won't have to \n",
    "# train it everytime u need it. To do this import pickle, use the dumps method and pass the estimator to it to persist the model.\n",
    "# import library for model persistence\n",
    "import pickle as pk1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x03csklearn.linear_model._logistic\\nLogisticRegression\\nq\\x00)\\x81q\\x01}q\\x02(X\\x07\\x00\\x00\\x00penaltyq\\x03X\\x02\\x00\\x00\\x00l2q\\x04X\\x04\\x00\\x00\\x00dualq\\x05\\x89X\\x03\\x00\\x00\\x00tolq\\x06G?\\x1a6\\xe2\\xeb\\x1cC-X\\x01\\x00\\x00\\x00Cq\\x07G?\\xf0\\x00\\x00\\x00\\x00\\x00\\x00X\\r\\x00\\x00\\x00fit_interceptq\\x08\\x88X\\x11\\x00\\x00\\x00intercept_scalingq\\tK\\x01X\\x0c\\x00\\x00\\x00class_weightq\\nNX\\x0c\\x00\\x00\\x00random_stateq\\x0bNX\\x06\\x00\\x00\\x00solverq\\x0cX\\x05\\x00\\x00\\x00lbfgsq\\rX\\x08\\x00\\x00\\x00max_iterq\\x0eM\\x10\\'X\\x0b\\x00\\x00\\x00multi_classq\\x0fX\\x04\\x00\\x00\\x00autoq\\x10X\\x07\\x00\\x00\\x00verboseq\\x11K\\x00X\\n\\x00\\x00\\x00warm_startq\\x12\\x89X\\x06\\x00\\x00\\x00n_jobsq\\x13NX\\x08\\x00\\x00\\x00l1_ratioq\\x14NX\\x08\\x00\\x00\\x00classes_q\\x15cnumpy.core.multiarray\\n_reconstruct\\nq\\x16cnumpy\\nndarray\\nq\\x17K\\x00\\x85q\\x18C\\x01bq\\x19\\x87q\\x1aRq\\x1b(K\\x01K\\x03\\x85q\\x1ccnumpy\\ndtype\\nq\\x1dX\\x02\\x00\\x00\\x00i4q\\x1eK\\x00K\\x01\\x87q\\x1fRq (K\\x03X\\x01\\x00\\x00\\x00<q!NNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\"b\\x89C\\x0c\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00q#tq$bX\\x05\\x00\\x00\\x00coef_q%h\\x16h\\x17K\\x00\\x85q&h\\x19\\x87q\\'Rq((K\\x01K\\x03K\\x04\\x86q)h\\x1dX\\x02\\x00\\x00\\x00f8q*K\\x00K\\x01\\x87q+Rq,(K\\x03h!NNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq-b\\x89C`\\x0f\\x9a\\x93\\xb8x(\\xdb\\xbf\\xbc\\xc5\\x1d \\x13\\xf1\\xee?\\x9c\\xe9\\xdb0>#\\x04\\xc0\\xcf\\xa5\\xfa\\xe0-E\\xf1\\xbf\\xbc[\\xa7f\\xa3\\x1e\\xe1?~\\xa7\\xc6\\x08\\x9f\\x90\\xd4\\xbf\\xed\\xb0\\xd6|\\xded\\xca\\xbf\\xa4\\xe1)3D7\\xee\\xbf\\x88s\\xecR8S\\xbc\\xbf\\xcdq\\xba\\x9b\\xc3\\xa8\\xe4\\xbf\\xa8T\\xa9\\x18\\x8c\\xc9\\x05@N\\xcbG\\xfdg0\\x00@q.tq/bX\\n\\x00\\x00\\x00intercept_q0h\\x16h\\x17K\\x00\\x85q1h\\x19\\x87q2Rq3(K\\x01K\\x03\\x85q4h,\\x89C\\x189\\xc3\\xc9t\\xd2\\xb5#@\\xb5\\x9c\\xa7\\\\\\xb7\\xdc\\x01@X\\xab\\xf3K\\x00-(\\xc0q5tq6bX\\x07\\x00\\x00\\x00n_iter_q7h\\x16h\\x17K\\x00\\x85q8h\\x19\\x87q9Rq:(K\\x01K\\x01\\x85q;h \\x89C\\x04{\\x00\\x00\\x00q<tq=bX\\x10\\x00\\x00\\x00_sklearn_versionq>X\\x06\\x00\\x00\\x000.22.1q?ub.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use dumps method to persist the model\n",
    "persist_model = pk1.dumps(logreg)\n",
    "persist_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sharv\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['regresfilename.pk1']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use joblib.dump to persist the model to a file\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(logreg,'regresfilename.pk1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use joblib.load to persist the model to a file\n",
    "# create new estimator from the saved model\n",
    "new_logreg_estimator = joblib.load('regresfilename.pk1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the new estimator\n",
    "new_logreg_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate and use new estimator to predict\n",
    "new_logreg_estimator.predict(X_new) # output is same as X_new object predicted earlier.\n",
    "# This proves that a model can b created, trained and persisted for future use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
